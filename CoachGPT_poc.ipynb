{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67a457ce",
   "metadata": {},
   "source": [
    "## Import Important Packages and Enviroment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c240a-240d-4479-98a8-c77832c5f2f9",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import random\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "load_dotenv('resources/conf.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "TEMPERTURE = float(os.getenv('TEMPERTURE'))\n",
    "MODEL = os.getenv('MODEL')\n",
    "MAX_TOKENS = int(os.getenv('MAX_TOKENS'))\n",
    "CHUNK_SIZE = int(os.getenv('CHUNK_SIZE'))\n",
    "CHUNK_OVERLAP  = int(os.getenv('CHUNK_OVERLAP'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d026898",
   "metadata": {},
   "source": [
    "## Define Important Helper Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd330ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_vector_product(vector_1, vector_2):\n",
    "    \"\"\"\n",
    "    This function calculates the inner vector product of two vectors.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    a = np.array(vector_1)\n",
    "    b = np.array(vector_2)\n",
    "\n",
    "    return np.dot(a, b)\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "class DbOps:\n",
    "    def __init__(self, db_name) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the DbOps class.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        db_name : str\n",
    "            The name of the SQLite database to connect to.\n",
    "        \"\"\"\n",
    "        # create a connection to the database\n",
    "        self.db_name = db_name\n",
    "        conn = sqlite3.connect(db_name)\n",
    "\n",
    "        # check if the table exists, if not create it\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='behavioral_question'\")\n",
    "        table_exists = cursor.fetchone()\n",
    "        \n",
    "        if not table_exists:\n",
    "            conn.execute('''CREATE TABLE behavioral_question\n",
    "                 (question TEXT,\n",
    "                 tags TEXT);''')\n",
    "        # close the connection\n",
    "        conn.close() \n",
    "    \n",
    "    def add_question(self, question, tags='-'):\n",
    "        \"\"\"\n",
    "        Adds a new question to the 'behavioral_question' table in the database.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        question : str\n",
    "            The question to add to the database.\n",
    "        tags : str, optional\n",
    "            The tags associated with the question. Default is '-'.\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect(self.db_name)\n",
    "        # insert a new question into the table\n",
    "        conn.execute(f\"INSERT INTO behavioral_question (question, tags) VALUES ('{question}', '{tags}')\")\n",
    "        # commit the changes\n",
    "        conn.commit()\n",
    "        # close the connection\n",
    "        conn.close()\n",
    "    \n",
    "    def get_random_element(self):\n",
    "        \"\"\"\n",
    "        Returns a random question from the 'behavioral_question' table in the database.\n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            A random question from the 'behavioral_question' table in the database.\n",
    "        \"\"\"\n",
    "        conn = sqlite3.connect(self.db_name)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM behavioral_question\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        random_index = random.randint(0, count-1)\n",
    "        cursor.execute(f\"SELECT question FROM behavioral_question LIMIT 1 OFFSET {random_index}\")\n",
    "        question = cursor.fetchone()[0]\n",
    "        conn.close()        \n",
    "        return question\n",
    "   \n",
    "    def populate_db(self, path_to_file):\n",
    "       with open(path_to_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "       \n",
    "       for line in lines:\n",
    "            question = line.strip()\n",
    "            self.add_question(question)\n",
    "\n",
    "def get_random_interview_question():\n",
    "        \"\"\"\n",
    "        This function returns a random interview question from the database.\n",
    "        \"\"\"\n",
    "        db = DbOps('resources/interview_questions.db')\n",
    "        db.populate_db('resources/sample_behavioral_questions.txt')\n",
    "        interview_question = db.get_random_element()\n",
    "        # Hard coded for Demo\n",
    "        #interview_question = 'How do you keep your team motivated during challenging times?'\n",
    "        return interview_question \n",
    "\n",
    "def get_transcript_from_youtube_video(video_id, file_path):\n",
    "    \"\"\"\n",
    "    Gets the transcript from a YouTube video.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    video_id : str\n",
    "        The ID of the YouTube video.\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The transcript of the YouTube video.\n",
    "    \"\"\"\n",
    "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    res = ''\n",
    "    for txt in transcript:\n",
    "        res += ' ' + txt['text']\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as interview:\n",
    "        interview.write(res) \n",
    "    return res\n",
    "\n",
    "def summarize_response(txt):\n",
    "    # Instantiate the LLM model\n",
    "    llm = OpenAI(temperature = TEMPERTURE, \n",
    "                 model = MODEL,\n",
    "                 max_tokens = MAX_TOKENS,\n",
    "                 openai_api_key = OPENAI_API_KEY)\n",
    "    \n",
    "    if len(txt) > int(CHUNK_SIZE) :\n",
    "        # Split text\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # Set a really small chunk size, just to show.\n",
    "        chunk_size = CHUNK_SIZE,\n",
    "        chunk_overlap  = CHUNK_OVERLAP,\n",
    "        length_function = len,\n",
    "        add_start_index = True)\n",
    "        \n",
    "        texts = text_splitter.split_text(txt)\n",
    "        # Create multiple documents\n",
    "        docs = [Document(page_content=t) for t in texts]\n",
    "        # Text summarization\n",
    "        chain = load_summarize_chain(llm, chain_type='map_reduce')\n",
    "        return chain.run(docs)\n",
    "    else:\n",
    "        return llm(txt)\n",
    "\n",
    "def calculate_similarity_to_leadership_principles(leadership_principles, \n",
    "                                                  summarized_response, \n",
    "                                                  random_story):\n",
    "    \"\"\"\n",
    "    This function calculates the similarity of the summarized response to the leadership principles.\n",
    "    \"\"\"\n",
    "    # Define embedding\n",
    "    embedding = OpenAIEmbeddings(client=None)\n",
    "\n",
    "    leadership_principles_embedding = {}\n",
    "    # Embedding leadership principles\n",
    "    for key, value in leadership_principles.items():\n",
    "        leadership_principles_embedding[key] = embedding.embed_query(value)\n",
    "\n",
    "    # Embedding summarized text, interviewee response\n",
    "    summarized_response_vector = embedding.embed_query(summarized_response)\n",
    "    # Embedding random story as a baseline\n",
    "    random_story_vector = embedding.embed_query(random_story)\n",
    "    # Normalize consider random story\n",
    "    baseline_weigth = inner_vector_product(summarized_response_vector, random_story_vector)\n",
    "\n",
    "    candidate_response_similarity_to_leadership_principles = {}\n",
    "\n",
    "    sum = 0.0\n",
    "    for key, value in leadership_principles_embedding.items():\n",
    "        candidate_response_similarity_to_leadership_principles[key] = abs(inner_vector_product(summarized_response_vector, value) - baseline_weigth)\n",
    "        sum += candidate_response_similarity_to_leadership_principles[key]\n",
    "\n",
    "    for key, value in candidate_response_similarity_to_leadership_principles.items():\n",
    "        candidate_response_similarity_to_leadership_principles[key] = (value/sum)*100\n",
    "\n",
    "    sorted_candidate_response_similarity_to_leadership_principles = sorted(candidate_response_similarity_to_leadership_principles.items(), \n",
    "                                                                key=lambda x:x[1], \n",
    "                                                                reverse=True)\n",
    "    return sorted_candidate_response_similarity_to_leadership_principles\n",
    "\n",
    "def plot_horizontal_bar_chart(data_dict):\n",
    "    \"\"\"\n",
    "    This function takes in a list of tuples of keys and values and plots them as a horizontal bar chart using matplotlib.\n",
    "    \"\"\"\n",
    "    keys = []\n",
    "    values = []\n",
    "\n",
    "    for item in data_dict:\n",
    "        keys.append(item[0])\n",
    "        values.append(item[1])\n",
    "        \n",
    "    l=[]\n",
    "    for i in range(0, len(keys)+1):\n",
    "        l.append(tuple(np.random.choice(range(0, 2), size=3)))\n",
    "\n",
    "    # Set the size of the figure\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # Create the horizontal bar chart with the extracted keys and values\n",
    "    plt.barh(keys[::-1], values[::-1], color=l, edgecolor='black', linewidth=1)\n",
    "\n",
    "    # Set the title and axis labels\n",
    "    plt.title('Similarity of the Interviewee\\'s Response to the Leadership Principles')\n",
    "    plt.xlabel('Percentage')\n",
    "    plt.ylabel('Leadership Principles')\n",
    "\n",
    "    # Show the horizontal bar chart\n",
    "    plt.show()\n",
    "\n",
    "def generate_pandas_df_from_dict(tuple_list):\n",
    "    \"\"\"\n",
    "        This function takes in a dictionary of keys and values and converts it into a pandas dataframe.\n",
    "    \"\"\"\n",
    "    keys = []\n",
    "    values = []\n",
    "\n",
    "    for item in tuple_list:\n",
    "        keys.append(item[0])\n",
    "        values.append(item[1])\n",
    "\n",
    "    return pd.DataFrame({\"Leadership Principles\":keys, \"Percentage\":values}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca20e4",
   "metadata": {},
   "source": [
    "## Prompt Template Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e111123",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_question_prompt = ''' We asked a candidate an interview question of {interview_question_asked}. \n",
    "Here is the summarized response: {candidate_response} \n",
    "\n",
    "Question : How do you evaluate the candidate's response?\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1) The story should be specific about an industrial project in the domain of \n",
    "   engineering, product or marketing.\n",
    "2) The story should be clear and easy to understand.\n",
    "3) The story should be relevant to the question.\n",
    "\n",
    "Please use the following template for your response :\n",
    "\n",
    "Your general ranking should be only one of these choices:\n",
    "\n",
    "1) weak, \n",
    "2) average, \n",
    "3) strong\n",
    "\n",
    "With the Explanation of your ranking. Create response like the follwoing format:\n",
    "\n",
    "\"ranking\": \"week\"; \n",
    "\"ai-explanation\": \"your explanation\"\n",
    "'''\n",
    "\n",
    "check_principles_promt ='''\n",
    "We asked a candidate an interview question. Here is the sumerized response: {candidate_response}\n",
    "\n",
    "Context: we have different leadership principles that we want to evaluate the candidate response against.\n",
    "Here is the list of leadership principles represented as a json string. Key is the leadership principle and value \n",
    "is the definition of the leadership principle.\n",
    "{leadership_principles}\n",
    "\n",
    "Question : Is candidate response relevant to this leadership principles?.\n",
    "\n",
    "Instructions:\n",
    "1) Validate your answer by highlighting the related text from the candidate response.\n",
    "2) Your Response should be less than 100 words.\n",
    "3) Use the format of principle name and your answer. \n",
    "\n",
    "For example, if you think the candidate response is relevant to the leadership principle \"Customer Obsession\", then your answer \n",
    "should look like \"Customer Obsession\": your answer. If it is not relevant to leadership principles, then write 'AI-could not get \n",
    "specific evidence in answer'. \n",
    "\n",
    "Create beautiful response like the follwoing format:\n",
    "\n",
    "1- \"principle_name\";\n",
    "\"ai-explanation\": \"your answer\";\n",
    "----------------------------------------------------------------------------------------------------\n",
    "2- \"principle_name\";\n",
    "\"ai-explanation\": \"your answer\";\n",
    "----------------------------------------------------------------------------------------------------\n",
    "...\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261dfb42",
   "metadata": {},
   "source": [
    "## Test Program on a Sample Input from YouTube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Open the random story response. It is used to define the baseline of similarity \n",
    "    # between the candidate response and random story.\n",
    "    with open('resources/random_story.txt', 'r') as f:\n",
    "        random_story = f.read()\n",
    "\n",
    "    # Load the leadership principles from the json file. This is used to evaluate the candidate response on how\n",
    "    # it is relevant to the leadership principles.\n",
    "    leadership_principles = read_json_file('resources/leadership_principles.json')\n",
    "\n",
    "    llm = OpenAI(temperature = TEMPERTURE, \n",
    "                 model = MODEL, \n",
    "                 max_tokens = MAX_TOKENS, \n",
    "                 openai_api_key = OPENAI_API_KEY)\n",
    "\n",
    "    # Get random question from the database \n",
    "    interview_question = \"Tell me about that you solved customer problem\"\n",
    "\n",
    "    # Get the response from user. In this part I assumed the response is on the youtube video.\n",
    "    res = get_transcript_from_youtube_video('CR8Niz9DrWU&t=6s', 'resources/interview_youtube.txt')\n",
    "\n",
    "    # Summarize the candidate response to the question\n",
    "    summerized_response = summarize_response(res)\n",
    "\n",
    "    # Create a prompt template to use in langchain\n",
    "\n",
    "    interview_question_prompt_template = PromptTemplate(\n",
    "        input_variables =[\"interview_question_asked\",\"candidate_response\"],\n",
    "        template = interview_question_prompt\n",
    "    )\n",
    "    interview_question_query = interview_question_prompt_template.format(\n",
    "            candidate_response = summerized_response,\n",
    "            interview_question_asked = interview_question\n",
    "        )\n",
    "\n",
    "    check_leadership_principle_prompt_template = PromptTemplate(\n",
    "        input_variables =[\"candidate_response\", \"leadership_principles\"],\n",
    "        template = check_principles_promt\n",
    "    )\n",
    "\n",
    "    # Create a prompt template to use in langchain for checking how it has leadership principles in high level\n",
    "    check_leadership_principle_prompt = check_leadership_principle_prompt_template.format(\n",
    "        candidate_response = summerized_response,\n",
    "        leadership_principles = json.dumps(leadership_principles))\n",
    "\n",
    "    # High level evaluation of the candidate response by AI\n",
    "    general_evaluation_by_ai_str = llm(interview_question_query)\n",
    "\n",
    "    # Detailed evaluation of the candidate response by AI\n",
    "    detailed_evaluation_by_ai_str = llm(check_leadership_principle_prompt)\n",
    "    \n",
    "    #Save the string to the JSON file\n",
    "    with open(\"outputs/general_evaluation_by_ai.txt\", \"w\") as f:\n",
    "        json.dump(general_evaluation_by_ai_str, f, indent=4) \n",
    "    f.close()\n",
    "\n",
    "    with open(\"outputs/detailed_evaluation_by_ai.txt\", \"w\") as f:\n",
    "        json.dump(detailed_evaluation_by_ai_str, f, indent=4)\n",
    "    f.close()   \n",
    "\n",
    "    sorted_candidate_response_similarity_to_leadership_principles = calculate_similarity_to_leadership_principles(leadership_principles, \n",
    "                                                                                                                    summerized_response, \n",
    "                                                                                                                            random_story)\n",
    "    plot_horizontal_bar_chart(sorted_candidate_response_similarity_to_leadership_principles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d637350",
   "metadata": {},
   "source": [
    "## POC GUI Design using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda370f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Open the random story response. It is used to define the baseline of similarity \n",
    "# between the candidate response and random story.\n",
    "with open('resources/random_story.txt', 'r') as f:\n",
    "    random_story = f.read()\n",
    "\n",
    "# Load the leadership principles from the json file. This is used to evaluate the candidate response on how\n",
    "# it is relevant to the leadership principles.\n",
    "leadership_principles = read_json_file('resources/leadership_principles.json')\n",
    "\n",
    "question = ''\n",
    "\n",
    "def generate_random_question():\n",
    "            question = get_random_interview_question()\n",
    "            return question\n",
    "\n",
    "llm = OpenAI(temperature = TEMPERTURE, \n",
    "             model = MODEL, \n",
    "             max_tokens = MAX_TOKENS, \n",
    "             openai_api_key = OPENAI_API_KEY)\n",
    "\n",
    "def evaluate_by_ai_interviewer(candidate_response_str):\n",
    "            \n",
    "            # Summarize the candidate response to the question\n",
    "            summarized_response_str = summarize_response(candidate_response_str)\n",
    "            \n",
    "            # Create a prompt template to use in langchain\n",
    "            interview_question_prompt_template = PromptTemplate(\n",
    "                input_variables =[\"interview_question_asked\",\"candidate_response\"],\n",
    "                template = interview_question_prompt\n",
    "            )\n",
    "            interview_question_query = interview_question_prompt_template.format(\n",
    "                    candidate_response = summarized_response_str,\n",
    "                    interview_question_asked = question\n",
    "                )\n",
    "\n",
    "            check_leadership_principle_prompt_template = PromptTemplate(\n",
    "                input_variables =[\"candidate_response\", \"leadership_principles\"],\n",
    "                template = check_principles_promt\n",
    "            )\n",
    "\n",
    "            # Create a prompt template to use in langchain for checking how it has leadership principles in high level\n",
    "            check_leadership_principle_prompt = check_leadership_principle_prompt_template.format(\n",
    "                candidate_response = summarized_response_str,\n",
    "                leadership_principles = json.dumps(leadership_principles))\n",
    "\n",
    "            sorted_tuple_list = calculate_similarity_to_leadership_principles(leadership_principles, summarized_response_str, random_story)\n",
    "    \n",
    "            data =  generate_pandas_df_from_dict(sorted_tuple_list) \n",
    "            \n",
    "            return { ai_evaluation:llm(interview_question_query),\n",
    "                    ai_detailed_evaluation:llm(check_leadership_principle_prompt),\n",
    "                    ai_similarity_analysis:data}\n",
    "\n",
    "with gr.Blocks() as coach_gpt_gradio_ui:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Welcome to the AI Behavioral Interviewer for Software Engineers, Managers and Product engineers 🎤\n",
    "    \n",
    "    ## 📝 Instructions :\n",
    "\n",
    "    1) Click on the button \"Generate Random Question\" to generate a random question.\n",
    "    2) Click on the button \"Evaluate By AI Interviewer\" to evaluate the candidate response.\n",
    "    \n",
    "    ## 📊 AI Analysis Inerpretation :\n",
    "    \n",
    "    The evaluation result will be displayed in the text box \"General Evaluation\" and \"Details Considering Different \n",
    "    Leadership Principles\". The decomposed response to leadership principles will be displayed in the image part using cosine \n",
    "    similarity for more insigths. It gives you a sense of how the candidate response is related/ranked to different leadership \n",
    "    principles. \n",
    "    \n",
    "    \"\"\")\n",
    "    with gr.Column():\n",
    "        btn_random_question = gr.Button(\"Generate Random Question\")\n",
    "        random_question = gr.Textbox(label=\"Behavioral Interview Question\", )\n",
    "        candidate_response_str = gr.Textbox(label=\"Candidate Response\", lines=20)\n",
    "        evaluate_by_ai = gr.Button(\"Evaluate By AI Interviewer\")\n",
    "        ai_evaluation = gr.Textbox(label= 'General Evaluation', lines=10)\n",
    "        ai_detailed_evaluation = gr.Textbox(label= 'Details Considering Different Leadership Principles', lines=20)\n",
    "        ai_similarity_analysis= gr.BarPlot( x = \"Leadership Principles\",\n",
    "                                            y = \"Percentage\",\n",
    "                                            x_title = \"Leadership Principles\",\n",
    "                                            y_title = \"Percentage\",\n",
    "                                            title = \"Similarity of the Interviewee's Response to the Leadership Principles\",\n",
    "                                            vertical = False,\n",
    "                                            height= 600,\n",
    "                                            width= 1000)\n",
    "\n",
    "        btn_random_question.click(fn=generate_random_question, \n",
    "                                  outputs=[random_question], \n",
    "                                  api_name=\"generate_random_question\")\n",
    "\n",
    "        evaluate_by_ai.click(\n",
    "                  fn=evaluate_by_ai_interviewer, \n",
    "                  inputs=[candidate_response_str], \n",
    "                  outputs = [ai_evaluation, ai_detailed_evaluation, ai_similarity_analysis], \n",
    "                  api_name=\"evaluate_by_ai_interviewer\")\n",
    "\n",
    "coach_gpt_gradio_ui.launch(width=600, height=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
